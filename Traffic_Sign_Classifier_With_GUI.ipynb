{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is Traffic Signs Recognition?\n",
    "### There are several different types of traffic signs like speed limits, no entry, traffic signals, turn left or right, children crossing, no passing of heavy vehicles, etc. Traffic signs classification is the process of identifying which class a traffic sign belongs to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image # pillow librabry to apen image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential,load_model\n",
    "from sklearn.model_selection import train_test_split # TO SPLIT DATA into train,test and validation\n",
    "from keras.layers import Conv2D,MaxPool2D,Dense,Flatten,Dropout\n",
    "from keras.utils import to_categorical  # it is used to convert y into one hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For this project, we are using the public dataset available at Kaggle\n",
    "### The dataset contains more than 50,000 images of different traffic signs. It is further classified into 43 different classes. The dataset is quite varying, some of the classes have many images while some classes have few images. The size of the dataset is around 300 MB. The dataset has a train folder which contains images inside each class and a test folder which we will use for testing our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\THAKUR ABHINAV'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()\n",
    "# os is used to manipluate files iterate over the folder|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‘train’ folder contains 43 folders each representing a different class. The range of the folder is from 0 to 42. With the help of the OS module, we iterate over all the classes and append images and their respective labels in the data and labels list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((39209, 30, 30, 3), (39209,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(r'C:\\Users\\THAKUR ABHINAV\\Downloads\\gtsrb-german-traffic-sign') # to change directory\n",
    "data=[]\n",
    "label=[]\n",
    "classes=43\n",
    "for i in range (classes):\n",
    "    path=os.path.join(os.getcwd(),'Train',str(i))\n",
    "    images=os.listdir(path)\n",
    "    \n",
    "    for a in images:\n",
    "        image=Image.open(path+'\\\\'+a)\n",
    "        image=image.resize((30,30))\n",
    "        image=np.array(image)\n",
    "        data.append(image)\n",
    "        label.append(i)\n",
    "        \n",
    "data=np.array(data)\n",
    "label=np.array(label)\n",
    "data.shape,label.shape\n",
    "# shape of image is(30,30,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0, ..., 42, 42, 42])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train shape (31367,)\n",
      "y_val shape (7842,)\n",
      "before hot encoding\n",
      "x_train shape (31367, 30, 30, 3)\n",
      "x_val shape (7842, 30, 30, 3)\n",
      "y_train shape (31367, 43)\n",
      "y_val shape (7842, 43)\n"
     ]
    }
   ],
   "source": [
    "x_train,x_val,y_train,y_val=train_test_split(data,label,test_size=0.2,random_state=42)\n",
    "print(\"y_train shape\",y_train.shape)\n",
    "print(\"y_val shape\",y_val.shape)\n",
    "print(\"before hot encoding\")\n",
    "y_train=to_categorical(y_train,43)\n",
    "y_val=to_categorical(y_val,43)\n",
    "print(\"x_train shape\", x_train.shape)\n",
    "print(\"x_val shape\" ,x_val.shape)\n",
    "print(\"y_train shape\", y_train.shape)\n",
    "print(\"y_val shape\", y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To classify the images into their respective categories, i will build a CNN model (Convolutional Neural Network). CNN is best for image classification purposes.\n",
    "\n",
    "### I compile the model with Adam optimizer which performs well and loss is “categorical_crossentropy” because we have multiple classes to categorise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\THAKUR ABHINAV\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\THAKUR ABHINAV\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu', input_shape=x_train.shape[1:]))\n",
    "model.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(rate=0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(rate=0.5))\n",
    "model.add(Dense(43, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\THAKUR ABHINAV\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\THAKUR ABHINAV\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 31367 samples, validate on 7842 samples\n",
      "Epoch 1/15\n",
      "31367/31367 [==============================] - 180s 6ms/step - loss: 4.4785 - acc: 0.1651 - val_loss: 2.0893 - val_acc: 0.5532\n",
      "Epoch 2/15\n",
      "31367/31367 [==============================] - 179s 6ms/step - loss: 1.7988 - acc: 0.5322 - val_loss: 0.9154 - val_acc: 0.7782\n",
      "Epoch 3/15\n",
      "31367/31367 [==============================] - 184s 6ms/step - loss: 1.0820 - acc: 0.7028 - val_loss: 0.4734 - val_acc: 0.8846\n",
      "Epoch 4/15\n",
      "31367/31367 [==============================] - 186s 6ms/step - loss: 0.7775 - acc: 0.7829 - val_loss: 0.3180 - val_acc: 0.9296\n",
      "Epoch 5/15\n",
      "31367/31367 [==============================] - 178s 6ms/step - loss: 0.6049 - acc: 0.8290 - val_loss: 0.2298 - val_acc: 0.9523\n",
      "Epoch 6/15\n",
      "31367/31367 [==============================] - 152s 5ms/step - loss: 0.4930 - acc: 0.8601 - val_loss: 0.1713 - val_acc: 0.9572\n",
      "Epoch 7/15\n",
      "31367/31367 [==============================] - 184s 6ms/step - loss: 0.4098 - acc: 0.8826 - val_loss: 0.1458 - val_acc: 0.9635\n",
      "Epoch 8/15\n",
      "31367/31367 [==============================] - 166s 5ms/step - loss: 0.3432 - acc: 0.9011 - val_loss: 0.1166 - val_acc: 0.9697\n",
      "Epoch 9/15\n",
      "31367/31367 [==============================] - 171s 5ms/step - loss: 0.3057 - acc: 0.9126 - val_loss: 0.0853 - val_acc: 0.9805\n",
      "Epoch 10/15\n",
      "31367/31367 [==============================] - 159s 5ms/step - loss: 0.2449 - acc: 0.9289 - val_loss: 0.0755 - val_acc: 0.9825\n",
      "Epoch 11/15\n",
      "31367/31367 [==============================] - 179s 6ms/step - loss: 0.2140 - acc: 0.9394 - val_loss: 0.0669 - val_acc: 0.9853\n",
      "Epoch 12/15\n",
      "31367/31367 [==============================] - 174s 6ms/step - loss: 0.1950 - acc: 0.9444 - val_loss: 0.0556 - val_acc: 0.9844\n",
      "Epoch 13/15\n",
      "31367/31367 [==============================] - 183s 6ms/step - loss: 0.1705 - acc: 0.9509 - val_loss: 0.0459 - val_acc: 0.9890\n",
      "Epoch 14/15\n",
      "31367/31367 [==============================] - 186s 6ms/step - loss: 0.1542 - acc: 0.9545 - val_loss: 0.0487 - val_acc: 0.9888\n",
      "Epoch 15/15\n",
      "31367/31367 [==============================] - 180s 6ms/step - loss: 0.1396 - acc: 0.9583 - val_loss: 0.0426 - val_acc: 0.9895\n"
     ]
    }
   ],
   "source": [
    "epochs = 15\n",
    "history = model.fit(x_train, y_train, batch_size=512,nb_epoch=epochs,verbose=1, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our model got a 95% accuracy on the training dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset contains a test folder and in a test.csv file, which have the details related to the image path and their respective class labels.Extract the image path and labels using pandas. Then to predict the model,I have to resize our images to 30×30 pixels and make a numpy array containing all image data. \n",
    "\n",
    "### From the sklearn.metrics, I imported the accuracy_score and observed how MY model predicted the actual labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pd.read_csv(r\"C:\\Users\\THAKUR ABHINAV\\Downloads\\gtsrb-german-traffic-sign\\Test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Width</th>\n",
       "      <th>Height</th>\n",
       "      <th>Roi.X1</th>\n",
       "      <th>Roi.Y1</th>\n",
       "      <th>Roi.X2</th>\n",
       "      <th>Roi.Y2</th>\n",
       "      <th>ClassId</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53</td>\n",
       "      <td>54</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>48</td>\n",
       "      <td>49</td>\n",
       "      <td>16</td>\n",
       "      <td>Test/00000.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42</td>\n",
       "      <td>45</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>36</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>Test/00001.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48</td>\n",
       "      <td>52</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>43</td>\n",
       "      <td>47</td>\n",
       "      <td>38</td>\n",
       "      <td>Test/00002.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>24</td>\n",
       "      <td>33</td>\n",
       "      <td>Test/00003.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>57</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>55</td>\n",
       "      <td>52</td>\n",
       "      <td>11</td>\n",
       "      <td>Test/00004.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12625</th>\n",
       "      <td>42</td>\n",
       "      <td>41</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>37</td>\n",
       "      <td>36</td>\n",
       "      <td>12</td>\n",
       "      <td>Test/12625.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12626</th>\n",
       "      <td>50</td>\n",
       "      <td>51</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>45</td>\n",
       "      <td>46</td>\n",
       "      <td>33</td>\n",
       "      <td>Test/12626.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12627</th>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>Test/12627.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12628</th>\n",
       "      <td>48</td>\n",
       "      <td>49</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>43</td>\n",
       "      <td>44</td>\n",
       "      <td>7</td>\n",
       "      <td>Test/12628.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12629</th>\n",
       "      <td>32</td>\n",
       "      <td>31</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "      <td>Test/12629.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12630 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Width  Height  Roi.X1  Roi.Y1  Roi.X2  Roi.Y2  ClassId            Path\n",
       "0         53      54       6       5      48      49       16  Test/00000.png\n",
       "1         42      45       5       5      36      40        1  Test/00001.png\n",
       "2         48      52       6       6      43      47       38  Test/00002.png\n",
       "3         27      29       5       5      22      24       33  Test/00003.png\n",
       "4         60      57       5       5      55      52       11  Test/00004.png\n",
       "...      ...     ...     ...     ...     ...     ...      ...             ...\n",
       "12625     42      41       5       6      37      36       12  Test/12625.png\n",
       "12626     50      51       6       5      45      46       33  Test/12626.png\n",
       "12627     29      29       6       6      24      24        6  Test/12627.png\n",
       "12628     48      49       5       6      43      44        7  Test/12628.png\n",
       "12629     32      31       6       5      27      26       10  Test/12629.png\n",
       "\n",
       "[12630 rows x 8 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "images=test['Path'].values ## path column contains the name of the image int test folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "images=test['Path'].values\n",
    "labels=test['ClassId'].values\n",
    "data2=[]\n",
    "for img in images:\n",
    "    image=Image.open(img)    \n",
    "    image=image.resize((30,30))\n",
    "    image=np.array(image)## conerting image to array\n",
    "    data2.append(image)\n",
    "x_test=np.array(data2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[116, 140, 175],\n",
       "         [116, 138, 171],\n",
       "         [119, 138, 173],\n",
       "         ...,\n",
       "         [102, 119, 150],\n",
       "         [101, 122, 149],\n",
       "         [ 93, 112, 139]],\n",
       "\n",
       "        [[116, 142, 177],\n",
       "         [116, 141, 175],\n",
       "         [117, 141, 174],\n",
       "         ...,\n",
       "         [120, 143, 178],\n",
       "         [122, 144, 176],\n",
       "         [122, 142, 174]],\n",
       "\n",
       "        [[118, 142, 174],\n",
       "         [116, 141, 175],\n",
       "         [114, 140, 172],\n",
       "         ...,\n",
       "         [121, 144, 181],\n",
       "         [122, 144, 180],\n",
       "         [119, 142, 178]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[117, 137, 168],\n",
       "         [115, 135, 165],\n",
       "         [116, 135, 164],\n",
       "         ...,\n",
       "         [116, 138, 170],\n",
       "         [116, 136, 168],\n",
       "         [118, 139, 171]],\n",
       "\n",
       "        [[116, 136, 166],\n",
       "         [115, 134, 167],\n",
       "         [115, 133, 165],\n",
       "         ...,\n",
       "         [114, 135, 168],\n",
       "         [116, 136, 166],\n",
       "         [115, 139, 167]],\n",
       "\n",
       "        [[112, 135, 166],\n",
       "         [111, 134, 165],\n",
       "         [119, 135, 166],\n",
       "         ...,\n",
       "         [115, 137, 166],\n",
       "         [117, 138, 167],\n",
       "         [114, 140, 170]]],\n",
       "\n",
       "\n",
       "       [[[ 62,  72,  61],\n",
       "         [ 89,  81,  63],\n",
       "         [ 94,  82,  65],\n",
       "         ...,\n",
       "         [ 78,  64,  68],\n",
       "         [ 72,  65,  67],\n",
       "         [ 74,  68,  68]],\n",
       "\n",
       "        [[ 64,  72,  60],\n",
       "         [ 97,  83,  65],\n",
       "         [ 97,  81,  63],\n",
       "         ...,\n",
       "         [ 75,  63,  65],\n",
       "         [ 93,  69,  71],\n",
       "         [ 88,  68,  68]],\n",
       "\n",
       "        [[ 59,  71,  60],\n",
       "         [ 91,  83,  66],\n",
       "         [ 95,  81,  63],\n",
       "         ...,\n",
       "         [ 68,  63,  63],\n",
       "         [ 76,  67,  68],\n",
       "         [ 78,  69,  70]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 52,  51,  46],\n",
       "         [ 81,  69,  58],\n",
       "         [ 80,  67,  57],\n",
       "         ...,\n",
       "         [ 70,  63,  63],\n",
       "         [ 83,  67,  66],\n",
       "         [ 78,  66,  67]],\n",
       "\n",
       "        [[ 53,  50,  48],\n",
       "         [ 80,  67,  62],\n",
       "         [ 78,  65,  59],\n",
       "         ...,\n",
       "         [ 59,  59,  61],\n",
       "         [ 67,  65,  64],\n",
       "         [ 72,  66,  66]],\n",
       "\n",
       "        [[ 54,  49,  48],\n",
       "         [ 80,  66,  62],\n",
       "         [ 78,  66,  58],\n",
       "         ...,\n",
       "         [ 62,  58,  61],\n",
       "         [ 72,  66,  69],\n",
       "         [ 75,  70,  70]]],\n",
       "\n",
       "\n",
       "       [[[ 52,  40,  38],\n",
       "         [ 51,  39,  37],\n",
       "         [ 50,  38,  37],\n",
       "         ...,\n",
       "         [ 52,  44,  47],\n",
       "         [ 54,  45,  48],\n",
       "         [ 55,  46,  48]],\n",
       "\n",
       "        [[ 60,  45,  42],\n",
       "         [ 59,  45,  41],\n",
       "         [ 57,  44,  40],\n",
       "         ...,\n",
       "         [ 51,  41,  40],\n",
       "         [ 53,  42,  43],\n",
       "         [ 54,  44,  43]],\n",
       "\n",
       "        [[ 68,  50,  46],\n",
       "         [ 66,  51,  46],\n",
       "         [ 68,  50,  46],\n",
       "         ...,\n",
       "         [ 59,  44,  40],\n",
       "         [ 57,  43,  40],\n",
       "         [ 57,  44,  41]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 27,  23,  25],\n",
       "         [ 28,  25,  27],\n",
       "         [ 28,  26,  29],\n",
       "         ...,\n",
       "         [ 25,  22,  23],\n",
       "         [ 26,  24,  23],\n",
       "         [ 27,  25,  25]],\n",
       "\n",
       "        [[ 31,  28,  29],\n",
       "         [ 36,  31,  33],\n",
       "         [ 40,  35,  37],\n",
       "         ...,\n",
       "         [ 33,  31,  28],\n",
       "         [ 38,  37,  35],\n",
       "         [ 44,  42,  42]],\n",
       "\n",
       "        [[ 33,  30,  31],\n",
       "         [ 35,  29,  29],\n",
       "         [ 47,  36,  34],\n",
       "         ...,\n",
       "         [ 41,  40,  37],\n",
       "         [ 44,  43,  43],\n",
       "         [ 48,  47,  44]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[ 24,  27,  34],\n",
       "         [ 23,  25,  32],\n",
       "         [ 24,  25,  32],\n",
       "         ...,\n",
       "         [ 26,  27,  33],\n",
       "         [ 26,  27,  34],\n",
       "         [ 26,  27,  34]],\n",
       "\n",
       "        [[ 25,  26,  33],\n",
       "         [ 25,  26,  34],\n",
       "         [ 26,  26,  33],\n",
       "         ...,\n",
       "         [ 26,  27,  34],\n",
       "         [ 27,  27,  35],\n",
       "         [ 28,  28,  36]],\n",
       "\n",
       "        [[ 26,  26,  32],\n",
       "         [ 25,  25,  32],\n",
       "         [ 24,  24,  30],\n",
       "         ...,\n",
       "         [ 26,  27,  33],\n",
       "         [ 27,  27,  33],\n",
       "         [ 27,  26,  33]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 16,  17,  21],\n",
       "         [ 15,  16,  21],\n",
       "         [ 14,  16,  21],\n",
       "         ...,\n",
       "         [ 19,  21,  29],\n",
       "         [ 21,  23,  33],\n",
       "         [ 19,  21,  30]],\n",
       "\n",
       "        [[ 16,  17,  22],\n",
       "         [ 15,  16,  21],\n",
       "         [ 14,  16,  21],\n",
       "         ...,\n",
       "         [ 19,  21,  30],\n",
       "         [ 20,  22,  32],\n",
       "         [ 19,  22,  32]],\n",
       "\n",
       "        [[ 15,  16,  21],\n",
       "         [ 15,  16,  21],\n",
       "         [ 14,  16,  21],\n",
       "         ...,\n",
       "         [ 18,  21,  30],\n",
       "         [ 19,  22,  32],\n",
       "         [ 18,  22,  31]]],\n",
       "\n",
       "\n",
       "       [[[ 46,  56,  71],\n",
       "         [ 48,  52,  65],\n",
       "         [ 58,  55,  57],\n",
       "         ...,\n",
       "         [ 42,  40,  50],\n",
       "         [ 15,  12,  15],\n",
       "         [  9,   8,  11]],\n",
       "\n",
       "        [[ 61,  69,  84],\n",
       "         [ 63,  61,  76],\n",
       "         [ 61,  59,  67],\n",
       "         ...,\n",
       "         [ 28,  26,  36],\n",
       "         [ 16,  12,  11],\n",
       "         [ 11,   9,  10]],\n",
       "\n",
       "        [[ 67,  75,  94],\n",
       "         [ 71,  79, 100],\n",
       "         [ 70,  78,  96],\n",
       "         ...,\n",
       "         [ 40,  42,  44],\n",
       "         [ 29,  24,  18],\n",
       "         [ 14,   8,   9]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 18,  18,  21],\n",
       "         [ 16,  16,  19],\n",
       "         [ 15,  14,  18],\n",
       "         ...,\n",
       "         [ 33,  32,  37],\n",
       "         [ 37,  38,  45],\n",
       "         [ 26,  26,  27]],\n",
       "\n",
       "        [[ 13,  12,  15],\n",
       "         [ 13,  12,  14],\n",
       "         [ 12,  10,  13],\n",
       "         ...,\n",
       "         [ 26,  27,  31],\n",
       "         [ 32,  34,  39],\n",
       "         [ 29,  29,  26]],\n",
       "\n",
       "        [[ 13,  11,  14],\n",
       "         [ 12,  11,  14],\n",
       "         [ 12,  10,  11],\n",
       "         ...,\n",
       "         [ 28,  31,  39],\n",
       "         [ 35,  37,  40],\n",
       "         [ 31,  29,  25]]],\n",
       "\n",
       "\n",
       "       [[[ 10,  10,  13],\n",
       "         [ 10,  10,  13],\n",
       "         [ 10,   9,  12],\n",
       "         ...,\n",
       "         [ 13,  12,  15],\n",
       "         [ 13,  12,  15],\n",
       "         [ 13,  12,  16]],\n",
       "\n",
       "        [[ 12,  11,  14],\n",
       "         [  9,   9,  12],\n",
       "         [  9,   9,  12],\n",
       "         ...,\n",
       "         [ 13,  12,  14],\n",
       "         [ 13,  12,  15],\n",
       "         [ 13,  12,  16]],\n",
       "\n",
       "        [[ 11,   9,  11],\n",
       "         [  9,   8,  11],\n",
       "         [  9,   9,  12],\n",
       "         ...,\n",
       "         [ 13,  12,  14],\n",
       "         [ 13,  12,  15],\n",
       "         [ 13,  12,  16]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 11,   9,  13],\n",
       "         [ 10,   9,  12],\n",
       "         [ 11,  10,  13],\n",
       "         ...,\n",
       "         [ 11,  10,  13],\n",
       "         [ 10,   9,  12],\n",
       "         [ 12,  11,  14]],\n",
       "\n",
       "        [[ 11,  10,  14],\n",
       "         [ 11,  10,  14],\n",
       "         [ 11,  10,  14],\n",
       "         ...,\n",
       "         [  9,   9,  12],\n",
       "         [  9,   9,  11],\n",
       "         [ 12,  11,  13]],\n",
       "\n",
       "        [[ 10,  10,  13],\n",
       "         [ 10,   9,  12],\n",
       "         [ 11,   9,  12],\n",
       "         ...,\n",
       "         [ 10,  10,  13],\n",
       "         [  9,  10,  12],\n",
       "         [ 11,  11,  13]]]], dtype=uint8)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict=model.predict_classes(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9631037212984956"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(labels,y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model achieved a 96% accuracy in this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('classifier96.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traffic Signs Classifier GUI(Graphical User Interface)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "import tkinter as tk\n",
    "from PIL import Image,ImageTk\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I build the GUI for uploading the image and a button is used to classify which calls the classify() function. The classify() function is converting the image into the dimension of shape (1, 30, 30, 3). This is because to predict the traffic sign we have to provide the same dimension which we have used when building the model. Then we predict the class, the model.predict_classes(image) returns us a number between (0-42) which represents the class it belongs to. I use the dictionary to get the information about the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import filedialog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = { 1:'Speed limit (20km/h)',\n",
    "            2:'Speed limit (30km/h)', \n",
    "            3:'Speed limit (50km/h)', \n",
    "            4:'Speed limit (60km/h)', \n",
    "            5:'Speed limit (70km/h)', \n",
    "            6:'Speed limit (80km/h)', \n",
    "            7:'End of speed limit (80km/h)', \n",
    "            8:'Speed limit (100km/h)', \n",
    "            9:'Speed limit (120km/h)', \n",
    "            10:'No passing', \n",
    "            11:'No passing veh over 3.5 tons', \n",
    "            12:'Right-of-way at intersection', \n",
    "            13:'Priority road', \n",
    "            14:'Yield', \n",
    "            15:'Stop', \n",
    "            16:'No vehicles', \n",
    "            17:'Veh > 3.5 tons prohibited', \n",
    "            18:'No entry', \n",
    "            19:'General caution', \n",
    "            20:'Dangerous curve left', \n",
    "            21:'Dangerous curve right', \n",
    "            22:'Double curve', \n",
    "            23:'Bumpy road', \n",
    "            24:'Slippery road', \n",
    "            25:'Road narrows on the right', \n",
    "            26:'Road work', \n",
    "            27:'Traffic signals', \n",
    "            28:'Pedestrians', \n",
    "            29:'Children crossing', \n",
    "            30:'Bicycles crossing', \n",
    "            31:'Beware of ice/snow',\n",
    "            32:'Wild animals crossing', \n",
    "            33:'End speed + passing limits', \n",
    "            34:'Turn right ahead', \n",
    "            35:'Turn left ahead', \n",
    "            36:'Ahead only', \n",
    "            37:'Go straight or right', \n",
    "            38:'Go straight or left', \n",
    "            39:'Keep right', \n",
    "            40:'Keep left', \n",
    "            41:'Roundabout mandatory', \n",
    "            42:'End of no passing', \n",
    "            43:'End no passing veh > 3.5 tons' }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root=tk.Tk()\n",
    "root.geometry('800x600')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "label=Label(root,background='yellow', font=('arial',15,'bold'))\n",
    "sign_image=Label(root)  #making label for image\n",
    "def classify(filepath):\n",
    "    global label_packed\n",
    "    image=Image.open(filepath)\n",
    "    image=image.resize((30,30))\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    image = np.array(image)\n",
    "    pred = model.predict_classes([image])[0]\n",
    "    sign = classes[pred+1]\n",
    "    print(sign)\n",
    "    label.configure(foreground='#011638', text=sign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_classify_button(file_path):\n",
    "    classify_b=Button(root,text=\"Classify Image\",command=lambda: classify(file_path),padx=10,pady=5)\n",
    "    classify_b.configure(background='#364156', foreground='white',font=('arial',10,'bold'))\n",
    "    classify_b.place(relx=0.79,rely=0.46)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_image():\n",
    "    try:\n",
    "        filepath=filedialog.askopenfilename()\n",
    "        upload=Image.open(filepath)\n",
    "        upload.thumbnail(((root.winfo_width()/2.25),(root.winfo_height()/2.25)))\n",
    "        im=ImageTk.PhotoImage(upload)\n",
    "\n",
    "            \n",
    "        sign_image.configure(image=im)\n",
    "        sign_image.image=im #taking a refrence\n",
    "        label.configure(text='')\n",
    "        show_classify_button(filepath)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "General caution\n"
     ]
    }
   ],
   "source": [
    "# upload button\n",
    "upload=Button(root,text=\"Upload an image\",command=upload_image,padx=10,pady=5)\n",
    "upload.configure(background='#364156', foreground='white',font=('arial',10,'bold'))\n",
    "upload.pack(side=BOTTOM,pady=50)\n",
    "label.pack(side=BOTTOM,expand=True)\n",
    "sign_image.pack(side=BOTTOM,expand=True)\n",
    "heading = Label(root, text=\"Know Your Traffic Sign\",pady=20, font=('arial',20,'bold'))\n",
    "heading.configure(background='#CDCDCD',foreground='#364156')\n",
    "heading.pack()\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
